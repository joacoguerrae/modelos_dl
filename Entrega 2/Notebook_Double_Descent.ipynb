{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Notebook: Double Descent**\n",
        "\n",
        "Nombre:\n",
        "\n",
        "Numero de estudiante:\n",
        "\n",
        "---\n",
        "\n",
        "Esta notebook investiga el fen贸meno **double descent** que ocurre en las Redes Neuronales.\n",
        "\n",
        "En el aprendizaje autom谩tico, a menudo esperamos que a medida que la capacidad de un modelo (por ejemplo, el n煤mero de par谩metros) aumenta, el error de entrenamiento disminuya y el error de prueba eventualmente aumente despu茅s de cierto punto (el cl谩sico \"overfitting\"). Sin embargo, el fen贸meno de Double Descent desaf铆a esta intuici贸n al mostrar que, en ciertos escenarios, a medida que la capacidad del modelo contin煤a aumentando m谩s all谩 del punto de overfitting, el error de prueba puede volver a disminuir.\n",
        "\n",
        "En esta notebook:\n",
        "\n",
        "- Utilizamos el dataset MNIST-1D que se puede encontrar en https://github.com/greydanus/mnist1d.\n",
        "- Entrenamos redes con diferentes capacidades (variando el n煤mero de unidades ocultas)\n",
        "- Analizamos c贸mo el ruido en las etiquetas del conjunto de entrenamiento influye en la forma de la curva Double Descent."
      ],
      "metadata": {
        "id": "L6chybAVFJW2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "K7GgWxh844P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar el dataset MNIST 1D\n",
        "!pip install git+https://github.com/greydanus/mnist1d"
      ],
      "metadata": {
        "id": "fn9BP5N5TguP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import mnist1d\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "DEVICE = str(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "print('Using:', DEVICE)"
      ],
      "metadata": {
        "id": "hFxuHpRqTgri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_noisy_mnist1d_dataset(noise_rate=0.0):\n",
        "    \"\"\"\n",
        "    Generates the MNIST-1D dataset with a specified amount of noise in the training labels.\n",
        "\n",
        "    Args:\n",
        "        noise_rate (float): The proportion of training labels to flip randomly.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the noisy dataset.\n",
        "    \"\"\"\n",
        "    args = mnist1d.data.get_dataset_args()\n",
        "    args.num_samples = 8000\n",
        "    args.train_split = 0.5\n",
        "    args.corr_noise_scale = 0.25\n",
        "    args.iid_noise_scale = 2e-2\n",
        "    data = mnist1d.data.get_dataset(args, path='./mnist1d_data.pkl',\n",
        "                                    download=False, regenerate=True)\n",
        "\n",
        "    # Add noise to training labels\n",
        "    for c_y in range(len(data['y'])):\n",
        "        random_number = random.random()\n",
        "        if random_number < noise_rate:\n",
        "            random_int = int(random.random() * 10)\n",
        "            data['y'][c_y] = random_int\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "-uNsLn0I6aPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = get_noisy_mnist1d_dataset(noise_rate=0.0)\n",
        "\n",
        "# The training and test input and outputs are in\n",
        "# data['x'], data['y'], data['x_test'], and data['y_test']\n",
        "print(\"Examples in training set: {}\".format(len(data['y'])))\n",
        "print(\"Examples in test set: {}\".format(len(data['y_test'])))\n",
        "print(\"Dimensionality of each example: {}\".format(data['x'].shape[-1]))"
      ],
      "metadata": {
        "id": "Yjb421NM6iLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_signals(xs, t, labels=None, ratio=2.6, zoom=1):\n",
        "    rows, cols = 1, 10\n",
        "    fig = plt.figure(figsize=[cols*1.5,rows*1.5*ratio], dpi=60)\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            ix = r*cols + c\n",
        "            x, t = xs[ix], t\n",
        "            ax = plt.subplot(rows,cols,ix+1)\n",
        "\n",
        "            # plot the data\n",
        "            plt.plot(x, t, 'k-', linewidth=2)\n",
        "            if labels is not None:\n",
        "                plt.title(\"label=\" + str(labels[ix]), fontsize=22)\n",
        "\n",
        "            plt.xlim(-zoom,zoom) ; plt.ylim(-zoom,zoom)\n",
        "            plt.gca().invert_yaxis() ; plt.xticks([], []), plt.yticks([], [])\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    plt.tight_layout() ; plt.show()\n",
        "    return fig\n",
        "\n",
        "\n",
        "# Sample 10 random examples from test\n",
        "num_test_examples = len(data['y_test'])\n",
        "sample_indices_test = random.sample(range(num_test_examples), 10)\n",
        "\n",
        "xs = data['x_test'][sample_indices_test]\n",
        "labels = data['y_test'][sample_indices_test]\n",
        "t = data['t']\n",
        "_ = plot_signals(xs, t, labels=labels, ratio=2.7, zoom=6)"
      ],
      "metadata": {
        "id": "7KaGmA5v8YoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a4745d3"
      },
      "source": [
        "Ahora definiremos la funci贸n `get_model`, encargada de construir nuestra red neuronal.\n",
        "\n",
        "**Tarea:**\n",
        "Completa la funci贸n `get_model` con las siguientes especificaciones:\n",
        "\n",
        "1. Define las dimensiones:\n",
        "    * Entrada (D_i): debe coincidir con la dimensionalidad de cada muestra del dataset MNIST-1D.\n",
        "    * Oculta (n_hidden): se recibe como argumento de la funci贸n.\n",
        "    * Salida (D_o): igual al n煤mero de clases.\n",
        "\n",
        "2. Crea una arquitectura secuencial con las siguientes capas:\n",
        "    - Capa lineal de entrada.\n",
        "    - Activaci贸n ReLU.\n",
        "    - Capa lineal oculta.\n",
        "    - Activaci贸n ReLU.\n",
        "    - Capa lineal de salida.\n",
        "\n",
        "3. Devuelve el modelo resultante."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(n_hidden):\n",
        "\n",
        "  D_i = ...    # Input dimensions\n",
        "  D_k = n_hidden   # Hidden dimensions\n",
        "  D_o = ...    # Output dimensions\n",
        "\n",
        "  # Completar\n",
        "  model = ...\n",
        "\n",
        "  # Return the model\n",
        "  return model ;"
      ],
      "metadata": {
        "id": "hAIvZOAlTnk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a17a5d50"
      },
      "source": [
        "## Entrenamiento y visualizaci贸n de la curva *Double Descent*\n",
        "\n",
        "En esta secci贸n vamos a explorar c贸mo var铆an el **error de entrenamiento** y el **error de prueba** al aumentar la capacidad de una red neuronal.\n",
        "\n",
        "**Tu tarea:**\n",
        "\n",
        "1. Entrena redes neuronales con distintos n煤meros de unidades ocultas (`n_hidden`) durante **1000 茅pocas**, usando los siguientes tama帽os de capa oculta:  \n",
        "   `[2, 10, 26, 45, 48, 50, 55, 70, 120, 200, 250]`.  \n",
        "2. Registra los errores finales de entrenamiento y prueba para cada modelo.  \n",
        "3. Grafica los errores en funci贸n del n煤mero de unidades ocultas para visualizar la **curva de Double Descent**.  \n",
        "4. A帽ade una l铆nea vertical que marque el **interpolation threshold**, que se puede representar como el punto en que el n煤mero de par谩metros del modelo se aproxima al n煤mero de ejemplos de entrenamiento. El pico del error de prueba suele aparecer cerca de esta regi贸n.\n",
        "\n",
        ">  **Nota:** la ejecuci贸n del c贸digo puede tomar un tiempo considerable, 隆as铆 que quiz谩s sea un buen momento para tomar un descanso!\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Su c贸digo aqui"
      ],
      "metadata": {
        "id": "38EsHjm2LR0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbf03cb7"
      },
      "source": [
        "## Explorando el *Double Descent* con etiquetas ruidosas\n",
        "\n",
        "En esta secci贸n repetiremos el experimento anterior, pero introduciendo **ruido en las etiquetas** del conjunto de entrenamiento para analizar c贸mo afecta al fen贸meno *Double Descent*.\n",
        "\n",
        "Entrenaremos nuevamente el modelo con los mismos tama帽os de capa oculta:  \n",
        "`[2, 10, 26, 45, 48, 50, 55, 70, 120, 200, 250]`,  \n",
        "pero esta vez usaremos datasets en los que un porcentaje de las etiquetas ha sido aleatorizado. Realizaremos el experimento con dos niveles de ruido: **10 %** y **30 %**.\n",
        "\n",
        "Despu茅s de entrenar los modelos para cada nivel de ruido, graficaremos las curvas de error de entrenamiento y prueba, similar a como lo hicimos anteriormente.\n",
        "\n",
        "**Tu tarea:**\n",
        "\n",
        "1. Ejecuta la celda siguiente para cargar los datasets con **10 %** y **30 %** de ruido.  \n",
        "2. Adapta el c贸digo de entrenamiento y visualizaci贸n de la secci贸n anterior para entrenar los modelos con los conjuntos ruidosos y graficar los resultados.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5272c808"
      },
      "source": [
        "# Carga el dataset MNIST-1D con 10% de ruido en las etiquetas de entrenamiento\n",
        "data_noisy_10 = get_noisy_mnist1d_dataset(noise_rate=0.10)\n",
        "\n",
        "# Puedes imprimir informaci贸n sobre el dataset ruidoso para verificarlo\n",
        "print(\"Dataset con 10% de ruido:\")\n",
        "print(\"Ejemplos en entrenamiento:\", len(data_noisy_10['y']))\n",
        "print(\"Ejemplos en prueba:\", len(data_noisy_10['y_test']))\n",
        "print(\"-\" * 20)\n",
        "\n",
        "# Repite el proceso para el 30% de ruido (modificando la tasa de ruido)\n",
        "data_noisy_30 = get_noisy_mnist1d_dataset(noise_rate=0.30)\n",
        "\n",
        "print(\"Dataset con 30% de ruido:\")\n",
        "print(\"Ejemplos en entrenamiento:\", len(data_noisy_30['y']))\n",
        "print(\"Ejemplos en prueba:\", len(data_noisy_30['y_test']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5efdcf3e"
      },
      "source": [
        "## Preguntas finales\n",
        "\n",
        "1. 驴C贸mo afecta el **ruido en las etiquetas** al error m铆nimo de entrenamiento alcanzable? 驴Por qu茅 ocurre esto?  \n",
        "2. Seg煤n tus observaciones, 驴c贸mo influye el **ruido en las etiquetas** en el fen贸meno de *Double Descent*, especialmente en relaci贸n con la **capacidad del modelo** y su **capacidad de generalizaci贸n**?  \n",
        "3. En *Deep Learning*, 驴es lo mismo el **overfitting** durante el entrenamiento que la **sobreparametrizaci贸n** de los modelos? Explica las diferencias.\n"
      ]
    }
  ]
}